# Creative Muse AI - Model Download Guide

Dieses Verzeichnis enth√§lt Scripts zum Download und Management von AI-Modellen f√ºr Creative Muse.

## üöÄ Schnellstart

### 1. Verf√ºgbare Modelle anzeigen
```bash
python scripts/download_models.py --list
```

### 2. Empfohlenes Modell herunterladen
```bash
python scripts/download_models.py --download mistral-7b-instruct-v0.3
```

### 3. Alle empfohlenen Modelle herunterladen
```bash
python scripts/download_models.py --download-all
```

### 4. Heruntergeladene Modelle anzeigen
```bash
python scripts/download_models.py --downloaded
```

## üìã Verf√ºgbare Kommandos

| Kommando | Beschreibung |
|----------|-------------|
| `--list` | Zeigt alle verf√ºgbaren Modelle |
| `--downloaded` | Zeigt heruntergeladene Modelle |
| `--download <model>` | L√§dt spezifisches Modell herunter |
| `--download-all` | L√§dt alle empfohlenen Modelle |
| `--force` | Erzwingt erneuten Download |
| `--test <model>` | Testet ein heruntergeladenes Modell |

## üîë Hugging Face Token Setup

F√ºr Mistral-Modelle ben√∂tigen Sie einen Hugging Face Token:

1. Erstellen Sie einen Account auf [Hugging Face](https://huggingface.co)
2. Gehen Sie zu [Settings > Access Tokens](https://huggingface.co/settings/tokens)
3. Erstellen Sie einen neuen Token mit "Read" Berechtigung
4. F√ºgen Sie den Token zur `.env` Datei hinzu:
   ```
   HF_TOKEN=your_token_here
   ```

## üì¶ Verf√ºgbare Modelle

### ‚≠ê Empfohlen: Mistral-7B-Instruct-v0.3
- **Gr√∂√üe:** ~14.5GB
- **Beschreibung:** Hauptmodell f√ºr Creative Muse
- **Voraussetzungen:** HF_TOKEN erforderlich
- **Download:** `python scripts/download_models.py --download mistral-7b-instruct-v0.3`

### Alternative Modelle

#### Mistral-7B-Instruct-v0.2
- **Gr√∂√üe:** ~14.5GB
- **Beschreibung:** Alternative Mistral Version
- **Voraussetzungen:** HF_TOKEN erforderlich

#### Microsoft DialoGPT-Medium
- **Gr√∂√üe:** ~1.5GB
- **Beschreibung:** Freies Modell f√ºr Tests
- **Voraussetzungen:** Keine

#### Microsoft DialoGPT-Large
- **Gr√∂√üe:** ~3GB
- **Beschreibung:** Gr√∂√üeres freies Modell
- **Voraussetzungen:** Keine

## üìÅ Model Cache Verzeichnis

Modelle werden standardm√§√üig in `./models/` gespeichert. Sie k√∂nnen das Verzeichnis √ºber die Umgebungsvariable `MODEL_CACHE_DIR` √§ndern:

```bash
export MODEL_CACHE_DIR=/path/to/your/models
```

## üß™ Modell testen

Nach dem Download k√∂nnen Sie ein Modell testen:

```bash
python scripts/download_models.py --test mistral-7b-instruct-v0.3
```

## üîÑ Modell erneut herunterladen

Falls ein Download unterbrochen wurde oder Sie das Modell aktualisieren m√∂chten:

```bash
python scripts/download_models.py --download mistral-7b-instruct-v0.3 --force
```

## üìä Speicherplatz-Anforderungen

| Modell | Speicherplatz | RAM (Minimum) | RAM (Empfohlen) |
|--------|---------------|---------------|-----------------|
| Mistral-7B-Instruct-v0.3 | 14.5GB | 8GB | 16GB+ |
| Mistral-7B-Instruct-v0.2 | 14.5GB | 8GB | 16GB+ |
| DialoGPT-Medium | 1.5GB | 4GB | 8GB |
| DialoGPT-Large | 3GB | 6GB | 12GB |

## üö® Troubleshooting

### Fehler: "HF_TOKEN nicht gefunden"
- Stellen Sie sicher, dass die `.env` Datei existiert
- √úberpr√ºfen Sie, dass `HF_TOKEN=your_token_here` in der `.env` Datei steht
- Verwenden Sie einen g√ºltigen Hugging Face Token

### Fehler: "Cannot instantiate tokenizer"
- Installieren Sie fehlende Abh√§ngigkeiten:
  ```bash
  pip install sentencepiece protobuf
  ```

### Fehler: "Out of memory"
- Schlie√üen Sie andere Anwendungen
- Verwenden Sie ein kleineres Modell f√ºr Tests
- Erh√∂hen Sie den verf√ºgbaren Speicher

### Download unterbrochen
- Verwenden Sie `--force` um den Download fortzusetzen
- √úberpr√ºfen Sie Ihre Internetverbindung

## üîß Integration mit Creative Muse

Nach dem Download wird das Modell automatisch von Creative Muse erkannt. Starten Sie das Backend:

```bash
cd ai_core
python main_llm.py
```

Das System erkennt automatisch verf√ºgbare Modelle und verwendet das beste verf√ºgbare Modell.

## üìù Logs und Debugging

Das Script verwendet Python Logging. F√ºr detaillierte Ausgaben:

```bash
export LOG_LEVEL=DEBUG
python scripts/download_models.py --download mistral-7b-instruct-v0.3
```

## ü§ù Support

Bei Problemen:
1. √úberpr√ºfen Sie die Logs
2. Stellen Sie sicher, dass alle Abh√§ngigkeiten installiert sind
3. √úberpr√ºfen Sie Ihren HF_TOKEN
4. Testen Sie mit einem kleineren Modell zuerst